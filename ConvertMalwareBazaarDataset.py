# Fixes the following in the Malware Bazaar dataset:
# 1. Removes unformatted info about the data that take up the first 8 rows. File name, terms of use, etc.
# 2. In a majority of columns there is extra quote (") characters around all cells and a space ( ) character at the start.
# 3. If a file has an alternate name, it is listed to the right of the first name.
#   This pushes data to the right of the name out of their columns and spills over in to untitled columns.
# 4. Adds a sequential integer ID that can be used as a primary key.
#
# Then it creates a mysql file for the dataset

import pandas as pd
import sqlite3
import csv

input_csv = "full.csv"
output_csv = "malwarebazaar_dataset.csv"
output_sqlite = "malware_hashes.db"
sqlite_table_name = "malware_hashes"

# New columns to add. These will contain alternate file names for the malware file if there is any.
altNameColumns = []
for i in range(1, 14):
    altNameColumns.append("alt_name" + str(i))

all_columns = [
    "first_seen_utc", "sha256_hash", "md5_hash", "sha1_hash", "reporter", "file_name",
    "file_type_guess", "mime_type", "signature", "clamav", "vtpercent",
    "imphash", "ssdeep", "tlsh"] + altNameColumns


# These columns are formatted incorrectly with quotes or empty characters around them.
columns_to_trim = [
    "sha256_hash", "md5_hash", "sha1_hash", "reporter", "file_name",
    "file_type_guess", "mime_type", "signature", "clamav", "vtpercent",
    "imphash", "ssdeep", "tlsh"] + altNameColumns

integer_columns = ["ID"]


# These columns are the ones that could have their data misaligned by alternate names being added.
columnsRightOfFile_Name = ["file_type_guess", "mime_type", "signature", "clamav", "vtpercent",
                           "imphash", "ssdeep", "tlsh"] + altNameColumns

# Columns that are unaffected by the alternate name shift
otherColumns = [
    "first_seen_utc", "sha256_hash", "md5_hash", "sha1_hash", "reporter", "file_name"
]

# Fix data shifted columns on rows where added alternate names pushed data to the right.
# Returns a dataframe with corrected rows.
def move_colums(df):
    shift_counts = 13 - df[altNameColumns].isna().sum(axis=1)

    newData = []

    for _, row in df.iterrows():
        shift_count = shift_counts.loc[_]
        if shift_count > 0:
            # Reconstruct the first part of the new row
            new_row = row[otherColumns].tolist()
            new_row.extend(row[columnsRightOfFile_Name[shift_count:shift_count + 8]].tolist())

            # Extract the altnames
            altNames = row[columnsRightOfFile_Name[0:shift_count]].tolist()

            # Fill in the alt_name# columns
            fixedAltNames = altNames + [None] * (len(altNameColumns) - len(altNames))  # Pad with None if needed

            new_row.extend(fixedAltNames)

            newData.append(new_row)
            if len(new_row) != 27:
                print("new_row" + str(_) + ": Isn't the correct length. It's " + str(len(new_row)))
        else:
            newData.append(row.tolist())
            if len(row) != 27:
                print("passed row" + str(_) + ": Isn't the correct length. It's " + str(len(row)))

    new_columns = otherColumns + columnsRightOfFile_Name
    return pd.DataFrame(newData, columns=new_columns)

# Trim extra quote and space characters from the start and end of data.
# Returns the trimmed value.
def trim_columns(value):
    if pd.isna(value) or len(value) < 3:
        return value  # Avoid errors for short or NaN values
    backTrim = 1
    frontTrim = 0

    if (value[1] == "\""):
        backTrim = 2

    if (value[-1] == "\""):
        frontTrim = -1
    return value[backTrim:frontTrim]


# Insert a new column at the beginning with sequential IDs
# Returns dataframe with new column
def add_primary_key(df):
    df.insert(0, 'ID', range(1, len(df) + 1))

    return df

print("Reading in " + input_csv + "...")
# The first 8 rows is unformatted info about the data. File name, terms of use, etc.
#   Row 9 is the header row. Replacing that with our own list as it fixes a name and adds some extra to fit in extra data.
df = pd.read_csv(input_csv, dtype=str, skiprows=9, names=all_columns)
df = df.drop(df.index[-1]) # Remove last line which is just a count of the amount of entries.

print("Moving columns...")
df = move_colums(df)

print("Trimming extra characters...")
df[columns_to_trim] = df[columns_to_trim].apply(lambda col: col.map(trim_columns))

print("Adding primary key column...")
df = add_primary_key(df)

print("Sorting table by sha1_hash column...")
df.sort_values(by="sha1_hash", inplace=True)

print("Writing csv file...")
df.to_csv(output_csv, index=False)

print("Writing sqlite database...")
conn = sqlite3.connect(output_sqlite)
cursor = conn.cursor()

with open(output_csv, newline='', encoding='utf-8') as csvfile:
    reader = csv.reader(csvfile)
    headers = next(reader)  # Get column names from the first row

    # Create table based on headers of the csv file. All columns as text except for the ID field
    columns = ", ".join([f'"{col}" INTEGER' if col in integer_columns 
                         else f'"{col}" TEXT' for col in headers])
    cursor.execute(f'CREATE TABLE "{sqlite_table_name}" ({columns});')

    # Insert data
    placeholders = ", ".join(["?" for _ in headers])
    insert_query = f'INSERT INTO "{sqlite_table_name}" VALUES ({placeholders})'

    for row in reader:
        cursor.execute(insert_query, row)

    cursor.execute(f'CREATE INDEX idx_sha1 ON "{sqlite_table_name}" ("sha1_hash");')

conn.commit()
conn.close()

print("Saved csv file to " + output_csv)
print("Saved sqlite database to " + output_sqlite)